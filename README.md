# ddp-tutorial-series
Follow the pytorch offlical tutorial to learn how to use nn.parallel.DistributedDataParallel to speed up training
